rm(list=ls())
options(stringsAsFactors = FALSE)
#For this early model, I will have the following variables that need estimates:
#Traits: SLA, ht, m.dbh, wood density, C:N
setwd("~/Documents/github/Treetraits")
source('Rcode/source/Cleaning_compiling_data.R')
comb<-comb[,(1:7,10:11 ]
comb<-comb[,c(1:7,10:11) ]
comb<-comb[,c(1:7,10:11) ]; head(comb)
comb<-comb[,c(1:7,10:11) ]; head(comb)
comb<-comb[,c(1:7,10:11) ]; comb
rm(list=ls())
options(stringsAsFactors = FALSE)
#For this early model, I will have the following variables that need estimates:
#Traits: SLA, ht, m.dbh, wood density, C:N
setwd("~/Documents/github/Treetraits")
source('Rcode/source/Cleaning_compiling_data.R')
comb<-comb[,c(1:7,10:11) ]; comb
source('Rcode/source/Cleaning_compiling_data.R')
head(comb)
str(comb)
comb<-comb[,c(1:7,10:11,20,25:27,32:34) ]; comb
str(comb)
source('Rcode/source/Cleaning_compiling_data.R')
head(comb)
comb<-comb[,c(1:7,10:11,20:21,26:27,32:34) ]; comb
str(comb)
source('Rcode/source/Cleaning_compiling_data.R')
head(comb)
unique(sp)
unique(comb$sp)
length(unique(comb$sp))
#Now I can prune the dataset to just the values I will be working with for this project
comb<-comb[,c(1:7,10:11,20:21,32:34) ]; comb
source('Rcode/source/Cleaning_compiling_data.R')
head(comb)
#Now I can prune the dataset to just the values I will be working with for this project
comb<-comb[,c(1:7,10:11,20:21,32:34) ]; comb
### Started January 29 2019 ###
## DL writing merging data for phenologyology and functional traits ##
#The aim of this code is to combine the phenologyology and functional trait data collected by DF in 2015
rm(list=ls())
options(stringsAsFactors = FALSE)
forlatex = TRUE # set to FALSE if just trying new figures, TRUE if outputting for final
runstan = FALSE # set to TRUE to actually run stan models. FALSE if loading from previous runs
# Analysis of bud burst experiment 2015.
library(memisc) # for getSummary
library(xtable)
library(scales) # for alpha
library(ggplot2)
library(caper) # for pgls
library(png) # readPNG for Fig 1
setwd("~/Documents/github/Treetraits")
#phenology<-read.csv("input/Budburst.csv", header=T, na.strings=c("","NA"))
(toload <- sort(dir("./input")[grep("Budburst Data", dir('./input'))], T)[1])
load(file.path("input", toload))
if(forlatex) figpath = "../docs/ms/images" else figpath = "graphs"
phenology<- dx
trt<-read.csv("input/Tree_Traits_2015.csv",header=T, na.strings=c("","NA"))
str(trt)
#remove columns of logistics (23-25)
trt<-trt[,c(1:12,18:22,26:29)]
#Start by changing column names in the datasets so they are least match
colnames(trt)[colnames(trt)=="Individual"] <- "ind"
colnames(trt)[colnames(trt)=="Site"] <- "site"
colnames(trt)[colnames(trt)=="Species"] <- "sp"
colnames(trt)[colnames(trt)=="X.N"] <- "per.N"
colnames(trt)[colnames(trt)=="X.C"] <- "per.C"
#Many of the columns are character, but should be numeric with NA
str(trt)
trt$DBH<-as.numeric(as.character(trt$DBH)); unique(trt$DBH)
trt$DBH.2<-as.numeric(as.character(trt$DBH.2)); unique(trt$DBH.2)
trt$DBH.3<-as.numeric(as.character(trt$DBH.3)); unique(trt$DBH.2)
trt$DBH.4<-as.numeric(as.character(trt$DBH.4)); unique(trt$DBH.2)
trt$DBH.5<-as.numeric(as.character(trt$DBH.5)); unique(trt$DBH.2)
str(trt)
trt$per.C<-as.numeric(as.character(trt$per.C)); unique(trt$per.C)
trt$per.N<-as.numeric(as.character(trt$per.N)); unique(trt$per.N)
names(phenology)
# head(phenology)
names(trt)
#head(trt)
#what Col should be in the new dataset used for Project 2 in 507?
# id, sp, rep, site, ind, treatcode, warm, photo, chill, Term.fl, Lat.fl, Term.lf, Lat.lf,tlea,leaf
#Individual, Site, Species, Latitude, Longitude, Elevation, Leaf.area, Fresh.mass, Dry.mass, Stem.vol, Stem.mass, Height, DBH, X.N, X.C, Stomatal. Length, Stomatal.Density
#Note that the individual ID are different between the two datasets; I am going to try and break them apart for sorting
# library(reshape2)
#
# #I don't fully understand what this code is doing, but it does work to split the character from the numeric parts of the species ID
# #https://stackoverflow.com/questions/9756360/split-character-data-into-numbers-and-letters
# temp<-colsplit(trt$Individual, "(?<=\\p{L})(?=[\\d+$])", c("char", "digit"))
#
# #A bit hacky,but the order appears to be the same, so this shouldn't be an issue.
# trt2<-cbind(trt,temp)
#
# #now doing the same for the phenologyology data
# tempphenology<-colsplit(phenology$id, "(?<=\\p{L})(?=[\\d+$])", c("char", "digit"))
#
#
# head(trt2)
#
# #Now paste them together to get a species ID that matches the one in the phenologyology dataset, need to further sep out replicates
# trt2$code<-paste(trt2$char, trt2$digit, sep = '_')
#
# head(trt2)
#Subset both for only the two populations both phenologyology and trait data were collected:
unique(phenology$site)
unique(trt$site)
trtsites<-subset(trt, site==c("SH","HF"))
#Now I want to put together the phenologyology dataset and the trait data. How inconsistent are these two datasets?
#Very different in length, what about the number of trees and
#Note id= twig level id
length(unique(phenology$ind)) #274
length(unique(trtsites$ind)) #2196
#I will think on this more, but here I am taking the mean of the phenologyology for a given combination of
require(plyr)
require(dplyr)
avg.phenology<-ddply(phenology, c("ind", "sp","site","treatcode","warm","photo","chill"), summarise,
Term.flm=mean(Term.fl, na.rm=TRUE),
Lat.flm=mean(Lat.fl, na.rm=TRUE),
# Term.lfm=mean(Term.lf, na.rm=TRUE),
# Lat.lfm=mean(Lat.lf, na.rm=TRUE),
tleafm=mean(tleaf, na.rm=TRUE),
lleafm=mean(lleaf, na.rm=TRUE))
new<-left_join(avg.phenology, trtsites, by= c("ind","sp","site"))
comb<-subset(new, Latitude>0 & Leaf.area>0)
#Now calculating the required traits: sla, wood density,
#want sla to be in mm^2/g
comb$Leaf.area.sq<-comb$Leaf.area*100
comb$Dry.mass.g<-comb$Dry.mass*1000
names(comb)
comb$sla<-comb$Leaf.area.sq/comb$Dry.mass.g
comb$wood.den<-comb$Stem.volume/comb$Stem.mass
#comb$m.dbh<-colMeans(comb[,26:30], na.rm=TRUE) #this doesn't do what it should
comb$cn<-(comb$per.C/comb$per.N)
str(comb)
#Now I can prune the dataset to just the values I will be working with for this project
comb<-comb[,c(1:7,10:11,20:21,32:34) ]; comb
#Now I can prune the dataset to just the values I will be working with for this project
comb<-comb[,c(1:7,10:11,20:21,32:34) ]; head(comb)
str(comb)
rm(list=ls())
options(stringsAsFactors = FALSE)
forlatex = TRUE # set to FALSE if just trying new figures, TRUE if outputting for final
runstan = FALSE # set to TRUE to actually run stan models. FALSE if loading from previous runs
# Analysis of bud burst experiment 2015.
library(memisc) # for getSummary
library(xtable)
library(scales) # for alpha
library(ggplot2)
library(caper) # for pgls
library(png) # readPNG for Fig 1
setwd("~/Documents/github/Treetraits")
#phenology<-read.csv("input/Budburst.csv", header=T, na.strings=c("","NA"))
(toload <- sort(dir("./input")[grep("Budburst Data", dir('./input'))], T)[1])
load(file.path("input", toload))
if(forlatex) figpath = "../docs/ms/images" else figpath = "graphs"
phenology<- dx
trt<-read.csv("input/Tree_Traits_2015.csv",header=T, na.strings=c("","NA"))
str(trt)
#remove columns of logistics (23-25)
trt<-trt[,c(1:12,18:22,26:29)]
#Start by changing column names in the datasets so they are least match
colnames(trt)[colnames(trt)=="Individual"] <- "ind"
colnames(trt)[colnames(trt)=="Site"] <- "site"
colnames(trt)[colnames(trt)=="Species"] <- "sp"
colnames(trt)[colnames(trt)=="X.N"] <- "per.N"
colnames(trt)[colnames(trt)=="X.C"] <- "per.C"
#Many of the columns are character, but should be numeric with NA
str(trt)
trt$DBH<-as.numeric(as.character(trt$DBH)); unique(trt$DBH)
trt$DBH.2<-as.numeric(as.character(trt$DBH.2)); unique(trt$DBH.2)
trt$DBH.3<-as.numeric(as.character(trt$DBH.3)); unique(trt$DBH.2)
trt$DBH.4<-as.numeric(as.character(trt$DBH.4)); unique(trt$DBH.2)
trt$DBH.5<-as.numeric(as.character(trt$DBH.5)); unique(trt$DBH.2)
str(trt)
trt$per.C<-as.numeric(as.character(trt$per.C)); unique(trt$per.C)
trt$per.N<-as.numeric(as.character(trt$per.N)); unique(trt$per.N)
names(phenology)
# head(phenology)
names(trt)
#head(trt)
#what Col should be in the new dataset used for Project 2 in 507?
# id, sp, rep, site, ind, treatcode, warm, photo, chill, Term.fl, Lat.fl, Term.lf, Lat.lf,tlea,leaf
#Individual, Site, Species, Latitude, Longitude, Elevation, Leaf.area, Fresh.mass, Dry.mass, Stem.vol, Stem.mass, Height, DBH, X.N, X.C, Stomatal. Length, Stomatal.Density
#Note that the individual ID are different between the two datasets; I am going to try and break them apart for sorting
# library(reshape2)
#
# #I don't fully understand what this code is doing, but it does work to split the character from the numeric parts of the species ID
# #https://stackoverflow.com/questions/9756360/split-character-data-into-numbers-and-letters
# temp<-colsplit(trt$Individual, "(?<=\\p{L})(?=[\\d+$])", c("char", "digit"))
#
# #A bit hacky,but the order appears to be the same, so this shouldn't be an issue.
# trt2<-cbind(trt,temp)
#
# #now doing the same for the phenologyology data
# tempphenology<-colsplit(phenology$id, "(?<=\\p{L})(?=[\\d+$])", c("char", "digit"))
#
#
# head(trt2)
#
# #Now paste them together to get a species ID that matches the one in the phenologyology dataset, need to further sep out replicates
# trt2$code<-paste(trt2$char, trt2$digit, sep = '_')
#
# head(trt2)
#Subset both for only the two populations both phenologyology and trait data were collected:
unique(phenology$site)
unique(trt$site)
trtsites<-subset(trt, site==c("SH","HF"))
#Now I want to put together the phenologyology dataset and the trait data. How inconsistent are these two datasets?
#Very different in length, what about the number of trees and
#Note id= twig level id
length(unique(phenology$ind)) #274
length(unique(trtsites$ind)) #2196
#I will think on this more, but here I am taking the mean of the phenologyology for a given combination of
require(plyr)
require(dplyr)
avg.phenology<-ddply(phenology, c("ind", "sp","site","treatcode","warm","photo","chill"), summarise,
Term.flm=mean(Term.fl, na.rm=TRUE),
Lat.flm=mean(Lat.fl, na.rm=TRUE),
# Term.lfm=mean(Term.lf, na.rm=TRUE),
# Lat.lfm=mean(Lat.lf, na.rm=TRUE),
tleafm=mean(tleaf, na.rm=TRUE),
lleafm=mean(lleaf, na.rm=TRUE))
new<-left_join(avg.phenology, trtsites, by= c("ind","sp","site"))
comb<-subset(new, Latitude>0 & Leaf.area>0)
#want sla to be in mm^2/g
comb$Leaf.area.sq<-comb$Leaf.area*100
comb$Dry.mass.g<-comb$Dry.mass*1000
names(comb)
comb$sla<-comb$Leaf.area.sq/comb$Dry.mass.g
comb$wood.den<-comb$Stem.volume/comb$Stem.mass
#comb$m.dbh<-colMeans(comb[,26:30], na.rm=TRUE) #this doesn't do what it should
comb$cn<-(comb$per.C/comb$per.N)
str(comb)
#Now I can prune the dataset to just the values I will be working with for this project
comb<-comb[,c(1:7,10:11,20:21,32:34) ]; head(comb)
rm(list=ls())
options(stringsAsFactors = FALSE)
#For this early model, I will have the following variables that need estimates:
#Traits: SLA, ht, m.dbh, wood density, C:N
setwd("~/Documents/github/Treetraits")
source('Rcode/source/Cleaning_compiling_data.R')
head(comb)
### Started January 29 2019 ###
## DL writing merging data for phenologyology and functional traits ##
#The aim of this code is to combine the phenologyology and functional trait data collected by DF in 2015
rm(list=ls())
options(stringsAsFactors = FALSE)
forlatex = TRUE # set to FALSE if just trying new figures, TRUE if outputting for final
runstan = FALSE # set to TRUE to actually run stan models. FALSE if loading from previous runs
# Analysis of bud burst experiment 2015.
library(memisc) # for getSummary
library(xtable)
library(scales) # for alpha
library(ggplot2)
library(caper) # for pgls
library(png) # readPNG for Fig 1
setwd("~/Documents/github/Treetraits")
#phenology<-read.csv("input/Budburst.csv", header=T, na.strings=c("","NA"))
(toload <- sort(dir("./input")[grep("Budburst Data", dir('./input'))], T)[1])
load(file.path("input", toload))
if(forlatex) figpath = "../docs/ms/images" else figpath = "graphs"
phenology<- dx
trt<-read.csv("input/Tree_Traits_2015.csv",header=T, na.strings=c("","NA"))
str(trt)
#remove columns of logistics (23-25)
trt<-trt[,c(1:12,18:22,26:29)]
#Start by changing column names in the datasets so they are least match
colnames(trt)[colnames(trt)=="Individual"] <- "ind"
colnames(trt)[colnames(trt)=="Site"] <- "site"
colnames(trt)[colnames(trt)=="Species"] <- "sp"
colnames(trt)[colnames(trt)=="X.N"] <- "per.N"
colnames(trt)[colnames(trt)=="X.C"] <- "per.C"
#Many of the columns are character, but should be numeric with NA
str(trt)
trt$DBH<-as.numeric(as.character(trt$DBH)); unique(trt$DBH)
trt$DBH.2<-as.numeric(as.character(trt$DBH.2)); unique(trt$DBH.2)
trt$DBH.3<-as.numeric(as.character(trt$DBH.3)); unique(trt$DBH.2)
trt$DBH.4<-as.numeric(as.character(trt$DBH.4)); unique(trt$DBH.2)
trt$DBH.5<-as.numeric(as.character(trt$DBH.5)); unique(trt$DBH.2)
str(trt)
trt$per.C<-as.numeric(as.character(trt$per.C)); unique(trt$per.C)
trt$per.N<-as.numeric(as.character(trt$per.N)); unique(trt$per.N)
names(phenology)
# head(phenology)
names(trt)
#head(trt)
#what Col should be in the new dataset used for Project 2 in 507?
# id, sp, rep, site, ind, treatcode, warm, photo, chill, Term.fl, Lat.fl, Term.lf, Lat.lf,tlea,leaf
#Individual, Site, Species, Latitude, Longitude, Elevation, Leaf.area, Fresh.mass, Dry.mass, Stem.vol, Stem.mass, Height, DBH, X.N, X.C, Stomatal. Length, Stomatal.Density
#Note that the individual ID are different between the two datasets; I am going to try and break them apart for sorting
# library(reshape2)
#
# #I don't fully understand what this code is doing, but it does work to split the character from the numeric parts of the species ID
# #https://stackoverflow.com/questions/9756360/split-character-data-into-numbers-and-letters
# temp<-colsplit(trt$Individual, "(?<=\\p{L})(?=[\\d+$])", c("char", "digit"))
#
# #A bit hacky,but the order appears to be the same, so this shouldn't be an issue.
# trt2<-cbind(trt,temp)
#
# #now doing the same for the phenologyology data
# tempphenology<-colsplit(phenology$id, "(?<=\\p{L})(?=[\\d+$])", c("char", "digit"))
#
#
# head(trt2)
#
# #Now paste them together to get a species ID that matches the one in the phenologyology dataset, need to further sep out replicates
# trt2$code<-paste(trt2$char, trt2$digit, sep = '_')
#
# head(trt2)
#Subset both for only the two populations both phenologyology and trait data were collected:
unique(phenology$site)
unique(trt$site)
trtsites<-subset(trt, site==c("SH","HF"))
#Now I want to put together the phenologyology dataset and the trait data. How inconsistent are these two datasets?
#Very different in length, what about the number of trees and
#Note id= twig level id
length(unique(phenology$ind)) #274
length(unique(trtsites$ind)) #2196
#I will think on this more, but here I am taking the mean of the phenologyology for a given combination of
require(plyr)
require(dplyr)
avg.phenology<-ddply(phenology, c("ind", "sp","site","treatcode","warm","photo","chill"), summarise,
Term.flm=mean(Term.fl, na.rm=TRUE),
Lat.flm=mean(Lat.fl, na.rm=TRUE),
# Term.lfm=mean(Term.lf, na.rm=TRUE),
# Lat.lfm=mean(Lat.lf, na.rm=TRUE),
tleafm=mean(tleaf, na.rm=TRUE),
lleafm=mean(lleaf, na.rm=TRUE))
new<-left_join(avg.phenology, trtsites, by= c("ind","sp","site"))
comb<-subset(new, Latitude>0 & Leaf.area>0)
#Now calculating the required traits: sla, wood density,
#want sla to be in mm^2/g
comb$Leaf.area.sq<-comb$Leaf.area*100
comb$Dry.mass.g<-comb$Dry.mass*1000
names(comb)
comb$sla<-comb$Leaf.area.sq/comb$Dry.mass.g
comb$wood.den<-comb$Stem.volume/comb$Stem.mass
#comb$m.dbh<-colMeans(comb[,26:30], na.rm=TRUE) #this doesn't do what it should
comb$cn<-(comb$per.C/comb$per.N)
str(comb)
#Now I can prune the dataset to just the values I will be working with for this project
comb<-comb[,c(1:7,10:11,20:21,29,32:34) ]; head(comb)
setwd("~/Documents/github/Treetraits")
source('Rcode/source/Cleaning_compiling_data.R')
head(comb)
str(comb)
cor<-comb[,10:15]
pairs(cor)
chart.Correlation(comb[,c(10:15)], histogram=TRUE, pch=19)
chart.Correlation(comb[,c(10:15)], histogram=FALSE, pch=19)
slav= rnorm(ntot, 5, 1);
htv=rnorm(ntot, 11, 3) #sigma should be really high (3m) bc it includes trees and woody shrubs
cnv=rnorm(ntot, 10, 2)
woodv=rnorm(ntot, 0.5, 0.05)
stomv=rnorm(ntot, 20, 5)
par(mfrow=c(2,3))
dens(slav)
dens(htv)
dens(cnv)
dens(woodv)
dens(stomv)
#randomly generating numbers for each trait based on what I think a small tree would be
#sitev=rnorm(ntot,5,2) #Ultimatley I will be pooling across sites, so this is not necessary at this point in time
slav= rnorm(ntot, 5, 1);
int<-11 # days into the experiment of bb
sigma<-2
nsite = 2 #number of sites
nsp = 28 #number of species
rep = 50 # I think the maximum number is 10, but for many it is closer to 5
ntot<-nsite*nsp*rep #2800
ntot
#Building the required dataframe for all of the replication and traits
#Assigning a categorical value to site?
site=gl(nsite, rep, length=ntot)
#randomly generating numbers for each trait based on what I think a small tree would be
#sitev=rnorm(ntot,5,2) #Ultimatley I will be pooling across sites, so this is not necessary at this point in time
slav= rnorm(ntot, 5, 1);
htv=rnorm(ntot, 11, 3) #sigma should be really high (3m) bc it includes trees and woody shrubs
cnv=rnorm(ntot, 10, 2)
woodv=rnorm(ntot, 0.5, 0.05)
stomv=rnorm(ntot, 20, 5)
par(mfrow=c(2,3))
dens(slav)
dens(htv)
dens(cnv)
dens(woodv)
dens(stomv)
slav= rnorm(ntot, 5, 1);
htv=rnorm(ntot, 11, 3) #sigma should be really high (3m) bc it includes trees and woody shrubs
cnv=rnorm(ntot, 10, 2)
woodv=rnorm(ntot, 0.5, 0.05)
stomv=rnorm(ntot, 20, 5)
#effect sizes
site.diff=2 # I think site 2 will be delayed by 2 days due to the 5 degree diff in lat
sladiff= -0.5
htdiff=0.5
cndiff=-0.5
wooddiff=0.3
stomdiff=1
phenfull<-vector()
for (i in 1:ntot){
phenfull[i]<-int+sladiff*slav[i]+htdiff*htv[i]+cndiff*cnv[i]+wooddiff*woodv[i]+stomdiff*stomv[i]+rnorm(1, 0, sigma)
}
range(phenfull)
summary(lm(phenfull~slav+htv+cnv+woodv+stomv))
###############################################
#Creating centered data:
# centering the x dummy data
mm.cent<-scale(mm[,3:7]);head(mm.cent)
mm <- model.matrix(~(site+slav+htv+cnv+woodv+stomv), data.frame(site,slav,htv,cnv,woodv,stomv))
mm
mm.cent<-scale(mm[,3:7]);head(mm.cent)
pairs(mm.cent)
mm.cent<-cbind(mm[,1:2], mm.cent)
head(mm.cent)
par(mfrow=c(1,1))
require(rethinking)
simplehist(phenfull, xlab="Day of budburst")
slav<-scale(slav)
htv<-scale(htv)
cnv<-scale(cnv)
woodv<-scale(woodv)
stomv<-scale(stomv)
phencent<-vector()
for (i in 1:ntot){
phencent[i]<-int+sladiff*slav[i]+htdiff*htv[i]+cndiff*cnv[i]+wooddiff*woodv[i]+stomdiff*stomv[i]+rnorm(1,0, sigma)
}
head(phencent)
#hist of sample distribution
simplehist(phencent)
#hist of sample distribution
simplehist(phencent, xlab="Budburst daty")
par(mfrow=c(2,3))
dens(slav)
dens(htv)
dens(cnv)
dens(woodv)
dens(stomv)
#hist of sample distribution
simplehist(phencent, xlab="Budburst daty")
fake<- data.frame(phenfull,mm.cent)
head(fake)
fakecent<- data.frame(phencent,mm.cent)
head(fakecent)
summary(lm(phenfull ~ (slav+htv+cnv+woodv+stomv), data = fake)) # sanity check
summary(lm(phencent ~ (slav+htv+cnv+woodv+stomv), data = fakecent)) # sanity check
temp<-lm(phencent ~ (slav+htv+cnv+woodv+stomv), data = fakecent)
full.m<- map(
alist(
phencent~dnorm(mu, sigmahere),
mu<-a+bsla*slav+bht*htv+bcn*cnv+bstom*stomv+bwood*woodv,
a~dnorm(0, 10),
bsla~dnorm(0, 10),
bht~dnorm(0, 10),
bcn~dnorm(0, 10),
bstom~dnorm(0, 10),
bwood~dnorm(0, 10),
sigmahere~dunif(0,10)
),
data=fakecent)
precis(full.m)
#Very small intervals when you plot the MAP values
plot(precis(full.m))
diag(vcov(full.m))
cov2cor(vcov(full.m))
cov2cor(vcov(full.m))
par(mfrow=c(2,3))
plot(phencent~slav, data=fakecent)
plot(phencent~htv, data=fakecent)
plot(phencent~cnv, data=fakecent)
plot(phencent~woodv, data=fakecent)
plot(phencent~stomv, data=fakecent)
install.packages("bayesplot")
library (bayesplot)
library(ggplot2)
pp_check(full.m)
pp_check(full.m, fun = "ecdf_overlay")
pp_check(full.m, fun = "hist", nrep=6)
pp_check(full.m, fun = "hist")
full.stan<- map2stan(
alist(
phencent~dnorm(mu, sigmahere),
mu<-a+bsla*slav+bht*htv+bcn*cnv+bstom*stomv+bwood*woodv,
a~dnorm(0, 10),
bsla~dnorm(0, 10),
bht~dnorm(0, 10),
bcn~dnorm(0, 10),
bstom~dnorm(0, 10),
bwood~dnorm(0, 10),
sigmahere~dunif(0,10)
),
data=fakecent)
precis(full.stan)
###############
library(rstan)
pp_check(full.stan)
pp_check(full.stan,
, plotfun = "boxplot", nreps = 6, notch = FALSE)
postcheck(full.stan, prob=0.9)
temp.seq <- 1:ntot
length()
for ( i in 1:ntot ) {
plot( phencent~slav, data=fakecent)
mu <- link( full.m , data=fakecent )
mu.mean <- apply( mu , 2 , mean )
mu.PI <- apply( mu , 2 , PI , prob=0.97 )
lines( temp.seq , mu.mean )
lines( temp.seq , mu.PI[1,] , lty=2 )
lines( temp.seq , mu.PI[2,] , lty=2 )
}
