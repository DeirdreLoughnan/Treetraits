library(tools)
library(xtable)
install.packages("xtable")
library(xtable)
options(SweaveSyntax="SweaveSyntaxNoweb")
fx <- inline::cxxfunction( signature(x = "integer", y = "numeric" ) , '
return ScalarReal( INTEGER(x)[0] * REAL(y)[0] ) ;
' )
fx( 2L, 5 )
rstan_options(auto_write = TRUE)
library(rstan)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
library(reshape2)  # For switching between long-form and wide-form data
library(ggplot2)  # For the posterior predictive model checking example
library(gridExtra)  # Also for the posterior predictive model checking example
library(devtools)
install_github("danielcfurr/edstan")
install.packages("devtools")
library(devtools)
install_github("danielcfurr/edstan")
# Load edstan
library(edstan)
preview_rows <- seq(from = 1, to = nrow(spelling), length.out = 10)
spelling[preview_rows, ]
par_bkp <- par(no.readonly = TRUE)
par(mfrow = c(1, 2))
# Left plot
person_scores <- apply(spelling[, 2:5], 1, sum)
person_counts <- table(person_scores)
barplot(person_counts, main = "Raw score distribution", xlab = "Raw score",
ylab = "Number of persons")
# Right plot
item_scores <- apply(spelling[, 2:5], 2, mean)
barplot(item_scores, main = "Proportion correct by item", ylab = "Proportion correct",
ylim = c(0, 1), xaxt = "n")
# x-axis with angled labels
text(x = 0.85 + (1:length(item_scores) - 1) * 1.2, y = -0.05, labels = names(item_scores),
xpd = TRUE, srt = 30, pos = 2)
# Return to previous plot presets
par(par_bkp)
rm(list=ls())
options(stringsAsFactors = FALSE)
## R code 8.1
num_weeks <- 1e5
positions <- rep(0,num_weeks); positions
current <- 10
for ( i in 1:num_weeks ) {
# record current position
positions[i] <- current
# flip coin to generate proposal
proposal <- current + sample( c(-1,1) , size=1 )
# now make sure he loops around the archipelago
if ( proposal < 1 ) proposal <- 10
if ( proposal > 10 ) proposal <- 1
# move?
prob_move <- proposal/current
current <- ifelse( runif(1) < prob_move , proposal , current )
}
## R code 8.2
library(rethinking)
data(rugged)
d <- rugged
d$log_gdp <- log(d$rgdppc_2000)
#here we are reducing the df from 200+ obs to just the ones we have nations for 170 0bs
dd <- d[ complete.cases(d$rgdppc_2000) , ]
mod.cont <- map2stan(
alist(
sleep_total ~ dnorm( mu , sigma ) ,
mu <- a + bbrain*brainwt + bbody*bodywt ,
a ~ dnorm(0,100),
bbrain ~ dnorm(0,10),
bbody ~ dnorm(0,10),
sigma ~ dunif(0,10)
) ,
data=msleep.final )
#A list of Stan warnings
rm(list=ls())
options(stringsAsFactors = FALSE)
msleep<-as.data.frame(msleep)
head(msleep)
str(msleep)
#Research Question:
#How well does vore, brainwt, sleep_cycle predict total sleep
msleep$vore
#Start by making a dummy variable for vore
msleep$v_omni <- ifelse( msleep$vore=="omni" , 1 , 0 )
msleep$v_carni <- ifelse( msleep$vore=="carni" , 1 , 0 )
msleep$v_insecti <- ifelse( msleep$vore=="insecti" , 1 , 0 )
#scale the continuous data
msleep$s_brainwt<-scale(msleep$brainwt); msleep$s_brainwt
msleep$s_bodywt<-scale(msleep$bodywt)
msleep$s_sleep_total<-scale(msleep$sleep_total)
head(msleep)
#1. Trim unneeded columns
# msleep.tm <- msleep[ , c("v_omni","v_carni","v_insecti","s_brainwt","s_bodywt","s_sleep_total") ]
# head(msleep.tm)
# str(msleep.tm)
msleep.tm <- msleep[ , c("v_omni","v_carni","v_insecti","brainwt","bodywt","sleep_total") ]
head(msleep.tm)
str(msleep.tm)
#2. Select for complete cases
msleep.final <- msleep.tm[ complete.cases(msleep.tm) , ]
str(msleep.final)
unique(msleep$vore)
dat<-msleep
rm(list=ls())
options(stringsAsFactors = FALSE)
dat<-msleep
dat<-msleep
data()
msleep
data(msleep)
require(datasets)
data()
msleep
install.packages("dslabs")
library("dslabs")
data(package="dslabs")
data()
?msleep
??msleep
data(msleep)
rm(list=ls())
options(stringsAsFactors = FALSE)
dat<-msleep
#Mammal sleep dat
#Mammal sleep dataset
#Can be converted from a tibbel to a df
msleep<-as.data.frame(msleep)
library(dplyr)
library(readr)
temp = list.files(pattern="*.csv")
myfiles = lapply(temp, read.delim)
myfiles = lapply(temp, read.csv)
comb<-read.csv("input/combined_traitpheno.csv")
str(comb)
length(unique(comb$sp))
d<-comb[,c(3,13,14, 16:19)]
d <- d[ complete.cases(d), ] #there are a lot of missing cases for height & many indivudals that have phenology, but not trait data
str(d)
length(unique(d$sp))
d$sp_in<-coerce_index(d$sp)
d_in<-d[,c(2:8)]
str(d_in)
length(unique(d_in$sp_in))
rm(list=ls())
options(stringsAsFactors = FALSE)
#For this early model, I will have the following variables:
#Traits: SLA, height (ht), m.dbh, wood density, C:N, & stomatal density
library(rethinking)
setwd("~/Documents/github/Treetraits")
#source('Rcode/Source/Cleaning_compiling_data.R') #Here I combined the budburst and trait data, averaging over individual trees for a given treatment
comb<-read.csv("input/combined_traitpheno.csv")
str(comb)
length(unique(comb$sp))
d<-comb[,c(3,13,14, 16:19)]
d <- d[ complete.cases(d), ] #there are a lot of missing cases for height & many indivudals that have phenology, but not trait data
str(d)
length(unique(d$sp))
d$sp_in<-coerce_index(d$sp)
d_in<-d[,c(2:8)]
str(d_in)
length(unique(d_in$sp_in))
write.csv(d_in, "frst507_standata.csv")
